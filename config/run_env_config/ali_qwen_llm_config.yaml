temperature: 0
max_tokens: 0
#示意，大概基于官方减去 20k
max_context_window: 200000
base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
api_key: 
timeout: 600              # LiteLLM 原生：建立连接及整体响应的最大等待时间 
stream_timeout: 20        # LiteLLM 原生：两个流式数据块之间的最大间隔时间
first_chunk_timeout: 20   # 应用层强制：连接建立+首包接收的最大时间（防止连接池死锁）
models:
- openai/qwen-plus
figure_models:
- google/具体参考 qwen 提供的生图模型
compressor_models:
- openai/qwen-plus
read_figure_models:
- openai/qwen-plus
