

temperature: 0
max_tokens: 0
max_context_window: 500000
base_url: https://openrouter.ai/api/v1
api_key: 
timeout: 600              # LiteLLM 原生：建立连接及整体响应的最大等待时间 
stream_timeout: 30        # LiteLLM 原生：两个流式数据块之间的最大间隔时间
first_chunk_timeout: 30   # 应用层强制：连接建立+首包接收的最大时间（防止连接池死锁）

models:
# 简单格式：如果不配置 url 和 key，默认使用用全局 api_key + base_url
- openai/google/gemini-3-flash-preview
# 对象格式：覆盖 api_key 和/或 base_url，使用其他供应商的模型。
- name: openai/qwen-plus
  api_key: 
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1

figure_models:
# 同理
- openai/google/gemini-3-flash-preview
- name: openai/qwen-vl-max
  api_key: 
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1

compressor_models:
- openai/google/gemini-3-flash-preview    # 用全局 key


thinking_models:
- openai/google/gemini-3-flash-preview    # thinking agent 专用模型

read_figure_models:
- openai/google/gemini-3-flash-preview    # 图片分析专用（ToolServer 侧 vision_tool text-only 模式使用）

# 多模态配置
multimodal: true           # 主模型（models）+ thinking agent 是否支持多模态图片嵌入
compressor_multimodal: true   # 压缩模型（compressor_models）是否支持多模态图片嵌入








