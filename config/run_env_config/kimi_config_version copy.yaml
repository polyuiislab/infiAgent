#样例文件，请替换到llm_config.yaml
temperature: 0
max_tokens: 0
max_context_window: 200000
base_url: https://api.moonshot.cn/v1
api_key: your_key
timeout: 600              # LiteLLM 原生：建立连接及整体响应的最大等待时间 
stream_timeout: 20        # LiteLLM 原生：两个流式数据块之间的最大间隔时间
first_chunk_timeout: 20   # 应用层强制：连接建立+首包接收的最大时间（防止连接池死锁）
models:
- openai/kimi-k2-thinking
figure_models:
#无效了
- google/gemini-3-pro-image-preview
compressor_models:
- openai/kimi-k2-thinking
read_figure_models:
- openai/kimi-latest
