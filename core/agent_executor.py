#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agentæ‰§è¡Œå™¨ - ä½¿ç”¨XMLç»“æ„åŒ–ä¸Šä¸‹æ–‡çš„æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
"""
from typing import Dict, List
import sys
import traceback

# Windowså…¼å®¹æ€§ï¼šè®¾ç½®UTF-8ç¼–ç 
try:
    from utils.windows_compat import setup_console_encoding
    setup_console_encoding()
except ImportError:
    pass

from services.llm_client import SimpleLLMClient, ChatMessage
from core.context_builder import ContextBuilder
from core.tool_executor import ToolExecutor
from utils.conversation_storage import ConversationStorage
from utils.event_emitter import get_event_emitter as get_jsonl_emitter

from .agent_event_emitter import AgentEventEmitter
from .event_handlers import ConsoleLogHandler, JsonlStreamHandler
from .events import *
from utils.windows_compat import safe_print


class AgentExecutor:
    """Agentæ‰§è¡Œå™¨ - æ­£ç¡®çš„XMLä¸Šä¸‹æ–‡æ¶æ„"""
    
    def __init__(
        self,
        agent_name: str,
        agent_config: Dict,
        config_loader,
        hierarchy_manager
    ):
        """åˆå§‹åŒ–Agentæ‰§è¡Œå™¨"""
        self.agent_name = agent_name
        self.agent_config = agent_config
        self.config_loader = config_loader
        self.hierarchy_manager = hierarchy_manager
        
        self._setup_event_emitter()

        # ä»é…ç½®ä¸­æå–ä¿¡æ¯
        self.available_tools = agent_config.get("available_tools", [])
        self.max_turns = 10000000
        requested_model = agent_config.get("model_type", "claude-3-7-sonnet-20250219")
        self.model_type = requested_model
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = SimpleLLMClient()
        self.llm_client.set_tools_config(config_loader.all_tools)
        
        # éªŒè¯å¹¶è°ƒæ•´æ¨¡å‹
        available_models = self.llm_client.models
        final_model = self.model_type
        if self.model_type not in available_models:
            final_model = available_models[0]
            self.event_emitter.dispatch(CliDisplayEvent(
                message=f"âš ï¸è¯·æ±‚çš„æ¨¡å‹ '{self.model_type}' ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­", style='warning'
            ))
            self.model_type = final_model
        
        self.event_emitter.dispatch(CliDisplayEvent(
            message=f"âœ…ä½¿ç”¨å›é€€æ¨¡å‹: {final_model}" if final_model != requested_model else f"âœ…ä½¿ç”¨è¯·æ±‚çš„æ¨¡å‹: {final_model}",
            style='success'
        ))

        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ„é€ å™¨ï¼ˆè´Ÿè´£å®Œæ•´ä¸Šä¸‹æ–‡æ„å»ºï¼‰
        self.context_builder = ContextBuilder(
            hierarchy_manager,
            agent_config=agent_config,
            config_loader=config_loader,
            llm_client=self.llm_client,
            max_context_window=self.llm_client.max_context_window
        )
        
        # åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨
        self.tool_executor = ToolExecutor(config_loader, hierarchy_manager)
        
        # åˆå§‹åŒ–å¯¹è¯å­˜å‚¨
        self.conversation_storage = ConversationStorage()
        
        # AgentçŠ¶æ€
        self.agent_id = None
        self.action_history, self.action_history_fact, self.pending_tools = [], [], []
        self.latest_thinking = ""
        self.first_thinking_done = False
        self.thinking_interval = 10
        self.tool_call_counter = 0

    def _setup_event_emitter(self):
        """åˆå§‹åŒ–äº‹ä»¶å‘å°„å™¨å¹¶æ³¨å†Œå¤„ç†å™¨"""
        self.event_emitter = AgentEventEmitter()
        self.event_emitter.register(ConsoleLogHandler())
        
        jsonl_emitter = get_jsonl_emitter()
        if jsonl_emitter.enabled:
            self.event_emitter.register(JsonlStreamHandler(enabled=True))
    
    def run(self, task_id: str, user_input: str) -> Dict:
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        self.event_emitter.dispatch(AgentStartEvent(agent_name=self.agent_name, task_input=user_input))

        # å­˜å‚¨ task_input ä¾›å‹ç¼©å™¨ä½¿ç”¨
        self.current_task_input = user_input

        # Agentå…¥æ ˆ
        self.agent_id = self.hierarchy_manager.push_agent(self.agent_name, user_input)

        # å°è¯•åŠ è½½å·²æœ‰çš„å¯¹è¯å†å²
        start_turn = self._load_state_from_storage(task_id)
        
        try:
            # é¦–æ¬¡thinkingï¼ˆåˆå§‹è§„åˆ’ï¼‰
            if start_turn == 0 and not self.first_thinking_done:
                self.event_emitter.dispatch(CliDisplayEvent(message=f"[{self.agent_name}] å¼€å§‹è¡ŒåŠ¨å‰è¿›è¡Œåˆå§‹è§„åˆ’..."))
                thinking_result = self._trigger_thinking(task_id, user_input, is_first=True)
                if thinking_result:
                    self.event_emitter.dispatch(CliDisplayEvent(message=f"[{self.agent_name}] åˆå§‹è§„åˆ’å®Œæˆ"))
                    self.latest_thinking = thinking_result
                    self.first_thinking_done = True
                    self.hierarchy_manager.update_thinking(self.agent_id, thinking_result)
                    self._save_state(task_id, user_input, 0)
        except Exception as e:
            self._handle_execution_error(e)
            # sys.exit(1) is called inside, so we don't need to return
        
        # å¼ºåˆ¶å·¥å…·è°ƒç”¨è®¡æ•°å™¨
        max_tool_try = 0

        # æ‰§è¡Œå¾ªç¯
        for turn in range(start_turn, self.max_turns):
            self.event_emitter.dispatch(CliDisplayEvent(message=f"\n--- ç¬¬ {turn + 1}/{self.max_turns} è½®æ‰§è¡Œ ---", style='separator'))
            
            try:
                # æ¯è½®å¼€å§‹å‰ä¿å­˜çŠ¶æ€
                self._save_state(task_id, user_input, turn)

                # æ£€æŸ¥å¹¶å‹ç¼©å†å²åŠ¨ä½œï¼ˆå¦‚æœè¶…è¿‡é™åˆ¶ï¼‰
                self._compress_action_history_if_needed()

                # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«é€šç”¨prompts + åŠ¨æ€ä¸Šä¸‹æ–‡ï¼‰
                full_system_prompt = self.context_builder.build_context(
                    task_id,  # æ·»åŠ task_idå‚æ•°
                    self.agent_id,
                    self.agent_name,
                    user_input,
                    action_history=self.action_history  # ä¼ å…¥å½“å‰çš„åŠ¨ä½œå†å²
                )
                
                # è°ƒç”¨LLMï¼ˆhistoryæ°¸è¿œåªæœ‰ä¸€æ¡ï¼‰
                #history = [ChatMessage(role="user", content="è¯·è¾“å‡ºä¸‹ä¸€ä¸ªåŠ¨ä½œ")]
                llm_response = self._execute_llm_call(full_system_prompt)
                
                if llm_response.status != "success":
                    error_result = {
                        "status": "error",
                        "output": "LLMè°ƒç”¨å¤±è´¥",
                        "error_information": llm_response.error_information
                    }
                    self.hierarchy_manager.pop_agent(self.agent_id, str(error_result))
                    return error_result

                if not llm_response.tool_calls:
                    # å¼ºåˆ¶å·¥å…·è°ƒç”¨æœºåˆ¶
                    max_tool_try += 1
                    self.event_emitter.dispatch(CliDisplayEvent(message=f"âš ï¸ LLMæœªè°ƒç”¨å·¥å…·ï¼Œç¬¬{max_tool_try}/5æ¬¡æé†’", style='warning'))
                    
                    if max_tool_try <= 5:
                        self.action_history.append({
                            "tool_name": "_no_tool_call",
                            "arguments": {},
                            "result": {
                                "status": "error",
                                "output": f"ç¬¬{max_tool_try}æ¬¡ï¼šLLMæœªè°ƒç”¨å·¥å…·ï¼Œè¯·åœ¨ä¸‹ä¸€è½®ä¸­å¿…é¡»è°ƒç”¨å·¥å…·"
                            }
                        })
                        self._save_state(task_id, user_input, turn)
                        continue
                    else:
                        # 5æ¬¡åä»ä¸è°ƒç”¨ï¼Œè§¦å‘thinkingå¹¶æŠ¥é”™
                        self.event_emitter.dispatch(CliDisplayEvent(message="âŒ 5æ¬¡æé†’åä»æœªè°ƒç”¨å·¥å…·ï¼Œè§¦å‘thinkingåˆ†æ", style='error'))
                        thinking_result = self._trigger_thinking(task_id, user_input, is_first=False)
                        # todo for jsonl: self.event_emitter.dispatch(ThinkingEvent(...)) å¼ºåˆ¶thinkingäº‹ä»¶
                        error_result = {
                            "status": "error",
                            "output": thinking_result or "å¤šæ¬¡æœªè°ƒç”¨å·¥å…·",
                            "error_information": "Agentæ‹’ç»è°ƒç”¨å·¥å…·"
                            }
                        self.hierarchy_manager.pop_agent(self.agent_id, str(error_result))
                        self.event_emitter.dispatch(AgentEndEvent(status='error', result=error_result))
                        return error_result
                # é‡ç½®è®¡æ•°å™¨ï¼ˆæˆåŠŸè°ƒç”¨äº†å·¥å…·ï¼‰
                max_tool_try = 0

                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in llm_response.tool_calls:
                    final_result = self._execute_tool_call(tool_call, task_id, user_input, turn)
                    if final_result:
                        self.event_emitter.dispatch(AgentEndEvent(status='success', result=final_result))
                        self.hierarchy_manager.pop_agent(self.agent_id, final_result.get("output", ""))
                        return final_result
                
                # æ£€æŸ¥æ˜¯å¦è¯¥è§¦å‘thinkingï¼ˆæ¯Nè½®å·¥å…·è°ƒç”¨ï¼‰
                if self.tool_call_counter % self.thinking_interval == 0:
                    self.event_emitter.dispatch(CliDisplayEvent(f"[{self.agent_name}] ç¬¬{self.tool_call_counter}è½®å·¥å…·è°ƒç”¨ï¼Œè§¦å‘thinkingåˆ†æ"))
                    thinking_result = self._trigger_thinking(task_id, user_input, is_first=False)
                    if thinking_result:
                        self.latest_thinking = thinking_result
                        self.hierarchy_manager.update_thinking(self.agent_id, thinking_result)
                        self._save_state(task_id, user_input, turn)
                        self.action_history = []
            
            except Exception as e:
                self._handle_execution_error(e)

        self.event_emitter.dispatch(CliDisplayEvent(message=f"\nâš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶: {self.max_turns}", style='error'))
        timeout_result = {"status": "error", "output": "æ‰§è¡Œè¶…è¿‡æœ€å¤§è½®æ¬¡é™åˆ¶", "error_information": f"Max turns {self.max_turns} exceeded"}
        self.hierarchy_manager.pop_agent(self.agent_id, str(timeout_result))
        self.event_emitter.dispatch(AgentEndEvent(status='error', result=timeout_result))
        return timeout_result

    def _load_state_from_storage(self, task_id: str) -> int:
        """ä»å­˜å‚¨åŠ è½½çŠ¶æ€, è¿”å›èµ·å§‹è½®æ¬¡."""
        loaded_data = self.conversation_storage.load_actions(task_id, self.agent_id)
        if not loaded_data:
            return 0

        self.action_history = loaded_data.get("action_history", [])
        self.action_history_fact = loaded_data.get("action_history_fact", [])
        self.pending_tools = loaded_data.get("pending_tools", [])
        self.latest_thinking = loaded_data.get("latest_thinking", "")
        self.first_thinking_done = loaded_data.get("first_thinking_done", False)
        self.tool_call_counter = loaded_data.get("tool_call_counter", 0)
        start_turn = loaded_data.get("current_turn", 0) + 1
        
        self.event_emitter.dispatch(CliDisplayEvent(
            message=f"ğŸ“‚ å·²åŠ è½½å¯¹è¯å†å²ï¼Œä»ç¬¬ {start_turn + 1} è½®ç»§ç»­\n   æ¸²æŸ“å†å²: {len(self.action_history)}æ¡, å®Œæ•´è½¨è¿¹: {len(self.action_history_fact)}æ¡"
        ))

        # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæˆï¼ˆæœ‰final_outputï¼‰
        for action in self.action_history_fact:
            if action.get("tool_name") == "final_output":
                final_result = action.get("result", {})
                self.event_emitter.dispatch(CliDisplayEvent(message=f"\nâœ… ä»»åŠ¡å·²å®Œæˆï¼Œç›´æ¥è¿”å›ä¹‹å‰çš„final_outputç»“æœ\n   çŠ¶æ€: {final_result.get('status')}", style='success'))
                return final_result
        
        # æ¢å¤pendingå·¥å…·ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.pending_tools:
            self.event_emitter.dispatch(CliDisplayEvent(message=f"ğŸ”„ å‘ç°{len(self.pending_tools)}ä¸ªpendingå·¥å…·ï¼Œæ¢å¤æ‰§è¡Œ..."))
            self._recover_pending_tools(task_id)

        return start_turn

    def _execute_llm_call(self, system_prompt: str):
        """æ‰§è¡ŒLLMè°ƒç”¨å¹¶åˆ†å‘äº‹ä»¶"""
        self.event_emitter.dispatch(LlmCallStartEvent(model=self.model_type, system_prompt=system_prompt))
        
        history = [ChatMessage(role="user", content="<å†å²åŠ¨ä½œ>æ˜¯ä½ ä¹‹å‰å·²ç»æ‰§è¡Œçš„åŠ¨ä½œï¼Œä¸è¦é‡å¤<å†å²åŠ¨ä½œ>å†…çš„åŠ¨ä½œï¼ï¼è¯·è¾“å‡ºä¸‹ä¸€ä¸ªåŠ¨ä½œ")]
        llm_response = self.llm_client.chat(
            history=history, model=self.model_type, system_prompt=system_prompt,
            tool_list=self.available_tools, tool_choice="required"
        )
        
        self.event_emitter.dispatch(LlmCallEndEvent(
            llm_output=llm_response.output, tool_calls=llm_response.tool_calls
        ))
        return llm_response

    def _execute_tool_call(self, tool_call: Dict, task_id: str, user_input: str, turn: int) -> Dict:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨å¹¶åˆ†å‘äº‹ä»¶"""
        # âœ… åœ¨ä¿å­˜ pending ä¹‹å‰ï¼Œä¸º level != 0 çš„å·¥å…·æ·»åŠ  uuid
        arguments_with_uuid = self._add_uuid_if_needed(tool_call.name, tool_call.arguments)
        
        # âœ… å…ˆæ ‡è®°ä¸ºpendingï¼ˆä¿å­˜å¸¦ uuid çš„å‚æ•°ï¼‰
        self.event_emitter.dispatch(ToolCallStartEvent(tool_name=tool_call.name, arguments=arguments_with_uuid))

        pending_tool = {"id": tool_call.id, "name": tool_call.name, "arguments": arguments_with_uuid, "status": "pending"}
        self.pending_tools.append(pending_tool)
        self._save_state(task_id, user_input, turn)  # ä¿å­˜pendingçŠ¶æ€

        # æ‰§è¡Œå·¥å…·ï¼ˆä½¿ç”¨å¸¦ uuid çš„å‚æ•°ï¼‰
        tool_result = self.tool_executor.execute(
            tool_call.name,
            arguments_with_uuid,
            task_id
        )

        # âœ… æ‰§è¡Œåä»pendingç§»é™¤
        self.pending_tools = [t for t in self.pending_tools if t["id"] != tool_call.id]
        
        # å‘é€å·¥å…·ç»“æœäº‹ä»¶
        self.event_emitter.dispatch(ToolCallEndEvent(
            tool_name=tool_call.name, status=tool_result.get('status', 'unknown'), result=tool_result
        ))

        # è®°å½•åŠ¨ä½œåˆ°å†å²ï¼ˆä½¿ç”¨å¸¦ uuid çš„å‚æ•°ï¼‰
        action_record = {"tool_name": tool_call.name, "arguments": arguments_with_uuid, "result": tool_result}

        # æ·»åŠ åˆ°å®Œæ•´è½¨è¿¹ï¼ˆæ°¸ä¸å‹ç¼©ï¼‰
        self.action_history_fact.append(action_record)

        # æ·»åŠ åˆ°æ¸²æŸ“å†å²ï¼ˆä¼šè¢«å‹ç¼©
        self.action_history.append(action_record)

        self.hierarchy_manager.add_action(self.agent_id, action_record)

        # å·¥å…·æ‰§è¡Œåä¿å­˜çŠ¶æ€
        self._save_state(task_id, user_input, turn)
        
        # å¢åŠ å·¥å…·è°ƒç”¨è®¡æ•°
        self.tool_call_counter += 1
        
        # å¦‚æœæ˜¯final_outputï¼Œè¿”å›ç»“æœ
        if tool_call.name == "final_output":
            return action_record
        return None

    def _handle_execution_error(self, e: Exception):
        """ç»Ÿä¸€å¤„ç†æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å¼‚å¸¸"""
        error_type, error_msg, tb = type(e).__name__, str(e), traceback.format_exc()
        error_display = f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œä»»åŠ¡å·²ä¸­æ–­\n{'â”'*40}\nğŸ”´ é”™è¯¯ç±»å‹: {error_type}\nğŸ“ é”™è¯¯ä¿¡æ¯: {error_msg}\n{'â”'*40}\n\nğŸ“‹ è¯¦ç»†å †æ ˆ:\n{tb}"
        if self.latest_thinking:
            error_display += f"\n\nğŸ’­ å½“å‰è¿›åº¦:\n{self.latest_thinking[:500]}\n"
        error_display += f"\n{'â”'*40}\nğŸ’¡ ä»»åŠ¡å·²ä¿å­˜åœ¨å½“å‰çŠ¶æ€ï¼Œè¯·:\n   1. æ ¹æ®é”™è¯¯ä¿¡æ¯æ’æŸ¥é—®é¢˜\n   2. é‡æ–°å¯åŠ¨ CLI å¹¶è¾“å…¥ /resume å‘½ä»¤æ¢å¤ä»»åŠ¡\n{'â”'*40}\n"
        
        self.event_emitter.dispatch(ErrorEvent(error_display=error_display))
        sys.exit(1)

    def _add_uuid_if_needed(self, tool_name: str, arguments: Dict) -> Dict:
        """
        ä¸º level != 0 çš„å·¥å…·æ·»åŠ  uuid åç¼€åˆ° task_input
        
        Args:
            tool_name: å·¥å…·åç§°
            arguments: åŸå§‹å‚æ•°
            
        Returns:
            å¤„ç†åçš„å‚æ•°ï¼ˆå¦‚æœéœ€è¦æ·»åŠ  uuidï¼Œè¿”å›æ–°å­—å…¸ï¼›å¦åˆ™è¿”å›åŸå­—å…¸ï¼‰
        """
        try:
            # è·å–å·¥å…·é…ç½®
            tool_config = self.config_loader.get_tool_config(tool_name)
            if tool_config.get("type") == "llm_call_agent" and tool_config.get("level", 0) != 0 and "task_input" in arguments:
                import uuid
                # åˆ›å»ºæ–°å­—å…¸ï¼ˆé¿å…ä¿®æ”¹åŸå§‹å‚æ•°ï¼‰
                new_args = arguments.copy()
                new_args["task_input"] += f" [call-{uuid.uuid4().hex[:8]}]"
                self.event_emitter.dispatch(CliDisplayEvent(message=f"   ğŸ”– ä¸º level {tool_config.get('level')} å·¥å…·æ·»åŠ  uuid åç¼€"))
                return new_args
        except Exception as e:
            self.event_emitter.dispatch(CliDisplayEvent(message=f"âš ï¸ æ·»åŠ  uuid æ—¶å‡ºé”™: {e}", style='warning'))
        # å…¶ä»–æƒ…å†µè¿”å›åŸå‚æ•°
        return arguments
    
    def _trigger_thinking(self, task_id: str, task_input: str, is_first: bool = False) -> str:
        """
        è§¦å‘Thinking Agentè¿›è¡Œåˆ†æ
        
        Args:
            task_id: ä»»åŠ¡ID
            task_input: ä»»åŠ¡è¾“å…¥
            is_first: æ˜¯å¦æ˜¯é¦–æ¬¡thinking
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            from services.thinking_agent import ThinkingAgent

            thinking_agent = ThinkingAgent()

            # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯
            full_system_prompt = self.context_builder.build_context(
                task_id,
                self.agent_id,
                self.agent_name,
                task_input,
                action_history=self.action_history
            )
            result = thinking_agent.analyze_first_thinking(
                task_description=task_input,
                agent_system_prompt=full_system_prompt,
                available_tools=self.available_tools,
                tools_config=self.config_loader.all_tools
            )
            # å‘é€ thinking äº‹ä»¶ï¼ˆå®Œæ•´å†…å®¹ï¼‰
            self.event_emitter.dispatch(ThinkingEvent(agent_name=self.agent_name, result=result, is_first=is_first))
            return result
        except Exception as e:
            # todo: thinking failed event
            raise Exception(str(e))

    def _compress_action_history_if_needed(self):
        """æ£€æŸ¥å¹¶å‹ç¼©å†å²åŠ¨ä½œï¼ˆå¦‚æœè¶…è¿‡ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ï¼‰"""
        if not self.action_history:
            return
        
        try:
            from services.action_compressor import ActionCompressor

            # åˆå§‹åŒ–å‹ç¼©å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if not hasattr(self, 'action_compressor'):
                self.action_compressor = ActionCompressor(self.llm_client)
            
            # ä½¿ç”¨æ–°çš„å‹ç¼©ç­–ç•¥ï¼ˆä¼ å…¥ thinking å’Œ task_inputï¼‰
            original_len = len(self.action_history)
            compressed = self.action_compressor.compress_if_needed(
                self.action_history,
                self.llm_client.max_context_window,
                thinking=self.latest_thinking,
                task_input=self.current_task_input
            )

            # å¦‚æœå‘ç”Ÿäº†å‹ç¼©ï¼Œæ›¿æ¢
            if len(compressed) < original_len:
                self.event_emitter.dispatch(CliDisplayEvent(message=f"âœ… å†å²åŠ¨ä½œå·²å‹ç¼©: {original_len}æ¡ â†’ {len(compressed)}æ¡", style='success'))
                self.action_history = compressed
        except Exception as e:
            self.event_emitter.dispatch(CliDisplayEvent(message=f"âš ï¸ å‹ç¼©å¤±è´¥: {e}", style='warning'))
            traceback.print_exc()
    
    def _recover_pending_tools(self, task_id: str):
        """æ¢å¤pendingçŠ¶æ€çš„å·¥å…·è°ƒç”¨"""
        for pending_tool in self.pending_tools[:]:  # å¤åˆ¶åˆ—è¡¨
            tool_name, tool_args = pending_tool['name'], pending_tool['arguments']
            try:
                self.event_emitter.dispatch(CliDisplayEvent(message=f"   ğŸ”„ æ¢å¤æ‰§è¡Œ: {tool_name}\n   ğŸ“‹ å‚æ•°: {tool_args}"))
                # todo: send recover event
                # é‡æ–°æ‰§è¡Œå·¥å…·
                tool_result = self.tool_executor.execute(
                    tool_name,
                    tool_args,
                    task_id
                )
                
                # è®°å½•ç»“æœ
                action_record = {
                    "tool_name": tool_name,
                    "arguments": tool_args,
                    "result": tool_result
                }

                self.action_history_fact.append(action_record)
                self.action_history.append(action_record)
                
                # ä»pendingç§»é™¤
                self.pending_tools.remove(pending_tool)
                
                self.event_emitter.dispatch(CliDisplayEvent(message=f"   âœ… æ¢å¤å®Œæˆ: {tool_name}", style='success'))
                
                # å¦‚æœæ˜¯final_outputï¼Œç›´æ¥è¿”å›
                if tool_name == "final_output":
                    return tool_result
            except Exception as e:
                self.event_emitter.dispatch(CliDisplayEvent(message=f"   âŒ æ¢å¤å¤±è´¥: {tool_name} - {e}", style='error'))
        # æ¸…ç©ºpendingåˆ—è¡¨
        self.pending_tools = []
    
    def _save_state(self, task_id: str, user_input: str, current_turn: int):
        """
        ä¿å­˜å½“å‰çŠ¶æ€
        
        Args:
            task_id: ä»»åŠ¡ID
            user_input: ç”¨æˆ·è¾“å…¥
            current_turn: å½“å‰è½®æ¬¡
        """
        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«XMLä¸Šä¸‹æ–‡ï¼‰
        full_system_prompt = self.context_builder.build_context(
            task_id,  # æ·»åŠ task_idå‚æ•°
            self.agent_id,
            self.agent_name,
            user_input,
            action_history=self.action_history  # ä¼ å…¥åŠ¨ä½œå†å²
        )

        # ä¿å­˜çŠ¶æ€ï¼ˆæ–°æ ¼å¼ï¼‰
        self.conversation_storage.save_actions(
            task_id=task_id,
            agent_id=self.agent_id,
            agent_name=self.agent_name,
            task_input=user_input,
            action_history=self.action_history,  # æ¸²æŸ“ç”¨ï¼ˆä¼šå‹ç¼©ï¼‰
            action_history_fact=self.action_history_fact,  # å®Œæ•´è½¨è¿¹ï¼ˆä¸å‹ç¼©ï¼‰
            pending_tools=self.pending_tools,  # å¾…æ‰§è¡Œçš„å·¥å…·
            current_turn=current_turn,
            latest_thinking=self.latest_thinking,
            first_thinking_done=self.first_thinking_done,
            tool_call_counter=self.tool_call_counter,
            system_prompt=full_system_prompt
        )


if __name__ == "__main__":
    from utils.config_loader import ConfigLoader
    from core.hierarchy_manager import get_hierarchy_manager
    
    # æµ‹è¯•
    config_loader = ConfigLoader("infiHelper")
    hierarchy_manager = get_hierarchy_manager("test_task")

    hierarchy_manager.start_new_instruction("æµ‹è¯•ä»»åŠ¡")

    # è·å–writing_agenté…ç½®
    agent_config = config_loader.get_tool_config("alpha_agent")

    safe_print(f"âœ… Agenté…ç½®: {agent_config.get('name')}")
    safe_print(f"   Tools: {len(agent_config.get('available_tools', []))}")
